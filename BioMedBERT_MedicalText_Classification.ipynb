{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarim711/BiomedBERT_Medical-Text_Classification/blob/main/BioMedBERT_MedicalText_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePLrbmyyYx2K"
      },
      "source": [
        "# Text classification with Tfidf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyzHtR7pat7I"
      },
      "outputs": [],
      "source": [
        "#load libraries necessary for TF-IDF classification\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import spacy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6TY8vbHYt_b"
      },
      "outputs": [],
      "source": [
        "#load corpus\n",
        "df = pd.read_csv(\"covid_df.csv\")\n",
        "df = df.sample(len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Zl51XB-bPl_"
      },
      "outputs": [],
      "source": [
        "def assign_train_test_split(df, train_size=0.8, valid_size=0.1, random_state=None):\n",
        "    df['Split'] = \"Test\"\n",
        "    train_indices = df.sample(frac=train_size, random_state=random_state).index\n",
        "    df.loc[train_indices, 'Split'] = \"Train\"\n",
        "\n",
        "    nb_valid = int(valid_size * len(df))\n",
        "    valid_indices = df.loc[df['Split'] == \"Test\"].sample(n=nb_valid, random_state=random_state).index\n",
        "    df.loc[valid_indices, 'Split'] = \"Valid\"\n",
        "\n",
        "    return df\n",
        "\n",
        "# Example usage:\n",
        "df = pd.read_csv(\"covid_df.csv\")\n",
        "df = assign_train_test_split(df, train_size=0.8, valid_size=0.1, random_state=42)\n",
        "df\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fEaGjxKigyT"
      },
      "outputs": [],
      "source": [
        "#Did your function work?\n",
        "# Assertion checks\n",
        "assert np.fabs(len(df[df[\"Split\"] == \"Train\"]) - len(df) * 0.8) < 10\n",
        "assert np.fabs(len(df[df[\"Split\"] == \"Valid\"]) - len(df) * 0.1) < 10\n",
        "assert np.fabs(len(df[df[\"Split\"] == \"Test\"]) - len(df) * 0.1) < 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqXbXuMxk6Wr"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\") #this could take a minute to download the first time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8gZQGiogxcN"
      },
      "outputs": [],
      "source": [
        "def clean(sentence):\n",
        "    sentence = nlp(sentence)\n",
        "    ret = []\n",
        "    for word in sentence:\n",
        "        if word.is_stop: continue\n",
        "        lem = word.lemma_\n",
        "        ret.append(lem)\n",
        "    spacy_cleaned = \" \".join(ret)\n",
        "    sent = re.sub('[^A-Za-z]', ' ', spacy_cleaned)\n",
        "    sent = re.sub('\\s+', ' ', sent)\n",
        "    return sent\n",
        "\n",
        "df[\"Abstract_Cleaned\"] = df[\"Abstract\"].apply(clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAp3RTnAj9Gu"
      },
      "outputs": [],
      "source": [
        "def get_tfidf_vectors_and_labels(df, split = \"Train\", max_features = 100):\n",
        "    #new TF-IDF vectorizer considering only the 1000 most common terms\n",
        "    vectorizer = TfidfVectorizer(max_features=max_features)\n",
        "    #compute the TF-IDF vectors for each cleaned abstract\n",
        "    vectorizer.fit(df[df.Split==\"Train\"][\"Abstract_Cleaned\"])\n",
        "    vectors = vectorizer.transform(df[df.Split==split][\"Abstract_Cleaned\"])\n",
        "\n",
        "    labels = df[df.Split==split][\"Year\"]\n",
        "    return vectors.toarray(), labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pk5f9aF5_SQd"
      },
      "outputs": [],
      "source": [
        "def get_tfidf_vectors_and_labels(df, split=\"Train\", max_features=100):\n",
        "    # New TF-IDF vectorizer considering only the specified number of most common terms\n",
        "    vectorizer = TfidfVectorizer(max_features=max_features)\n",
        "\n",
        "    # Compute the TF-IDF vectors for each cleaned abstract in the training set\n",
        "    vectorizer.fit(df[df.Split == \"Train\"][\"Abstract_Cleaned\"])\n",
        "\n",
        "    # Get the TF-IDF vectors for the specified split\n",
        "    vectors = vectorizer.transform(df[df.Split == split][\"Abstract_Cleaned\"]).toarray()\n",
        "\n",
        "    # Get the labels for the specified split\n",
        "    labels = df[df.Split == split][\"Year\"]\n",
        "\n",
        "\n",
        "    return vectors, labels\n",
        "\n",
        "\n",
        "train_vectors, train_labels = get_tfidf_vectors_and_labels(df, split=\"Train\", max_features=100)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QII0ikJMYLxU"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(max_features=100)\n",
        "vectorizer.fit(df[df.Split == \"Train\"][\"Abstract_Cleaned\"])\n",
        "\n",
        "vocabulary = vectorizer.get_feature_names_out()\n",
        "vocabulary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbAjmsWhJDBf"
      },
      "outputs": [],
      "source": [
        "years_distribution = df[\"Year\"].value_counts().sort_index()\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(years_distribution.index, years_distribution.values, color='skyblue')\n",
        "plt.title('Distribution of Years')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vc0HEnZYmnz3"
      },
      "outputs": [],
      "source": [
        "# 1. Train and return the classifier\n",
        "def train_tfidf_classifier(vectors_train, labels_train):\n",
        "    model = LogisticRegression()\n",
        "    model.fit(vectors_train, labels_train)\n",
        "    return model\n",
        "\n",
        "# 2. Predict and return metrics\n",
        "def evaluate_model(model, vectors, labels, average='macro'):\n",
        "    predictions = model.predict(vectors)\n",
        "    f1 = f1_score(labels, predictions, average=average)\n",
        "    return predictions, f1\n",
        "\n",
        "# 3. Plot confusion matrix\n",
        "def plot_confusion_matrix(y_true, y_pred, class_labels, title=\"Confusion Matrix\"):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                xticklabels=class_labels, yticklabels=class_labels)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Predicted Class\")\n",
        "    plt.ylabel(\"True Class\")\n",
        "    plt.show()\n",
        "\n",
        "# 4. Final test evaluation (e.g. after tuning)\n",
        "def run_final_evaluation(df, max_features, class_labels):\n",
        "    # Get vectors & labels\n",
        "    vectors_train, labels_train = get_tfidf_vectors_and_labels(df, split=\"Train\", max_features=max_features)\n",
        "    vectors_test, labels_test = get_tfidf_vectors_and_labels(df, split=\"Test\", max_features=max_features)\n",
        "\n",
        "    # Train and evaluate\n",
        "    model = train_tfidf_classifier(vectors_train, labels_train)\n",
        "    predictions_test, _ = evaluate_model(model, vectors_test, labels_test)\n",
        "\n",
        "    # Confusion matrix\n",
        "    plot_confusion_matrix(labels_test, predictions_test, class_labels, title=\"TF-IDF Confusion Matrix\")\n",
        "\n",
        "# 5. Hyperparameter tuning across different max_features values\n",
        "def find_best_max_features(df, max_features_list):\n",
        "    f1_scores_train = []\n",
        "    f1_scores_valid = []\n",
        "    best_max_features = None\n",
        "    best_f1_valid = 0.0\n",
        "\n",
        "    for max_features in max_features_list:\n",
        "        vectors_train, labels_train = get_tfidf_vectors_and_labels(df, split=\"Train\", max_features=max_features)\n",
        "        vectors_valid, labels_valid = get_tfidf_vectors_and_labels(df, split=\"Valid\", max_features=max_features)\n",
        "\n",
        "        model = train_tfidf_classifier(vectors_train, labels_train)\n",
        "\n",
        "        _, f1_train = evaluate_model(model, vectors_train, labels_train)\n",
        "        _, f1_valid = evaluate_model(model, vectors_valid, labels_valid)\n",
        "\n",
        "        f1_scores_train.append(f1_train)\n",
        "        f1_scores_valid.append(f1_valid)\n",
        "\n",
        "        if f1_valid > best_f1_valid:\n",
        "            best_f1_valid = f1_valid\n",
        "            best_max_features = max_features\n",
        "\n",
        "    # Plot\n",
        "    plt.plot(np.arange(len(max_features_list)), f1_scores_train, label=\"F1 Train\")\n",
        "    plt.plot(np.arange(len(max_features_list)), f1_scores_valid, label=\"F1 Valid\")\n",
        "    plt.xticks(np.arange(len(max_features_list)), max_features_list)\n",
        "    plt.xlabel(\"Vocabulary size (max_features)\")\n",
        "    plt.ylabel(\"F1 Score (Macro)\")\n",
        "    plt.title(\"TF-IDF Performance Tuning\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\nOptimal max_features: {best_max_features} (Validation F1 Score: {best_f1_valid:.4f})\")\n",
        "    return best_max_features\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AtyDKmzTg9o"
      },
      "outputs": [],
      "source": [
        "best_max_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZJeRD81S95r"
      },
      "outputs": [],
      "source": [
        "# Define the max_features array you want to test (vocabulary sizes)\n",
        "max_features_list = [5, 10, 100, 500, 1000]\n",
        "\n",
        "#  Tune the max_features to get the best one\n",
        "best_max_features = find_best_max_features(df, max_features_list)\n",
        "\n",
        "# Run final evaluation on the test set with the best_max_features\n",
        "class_labels = [\"Class 0\", \"Class 1\", \"Class 2\", \"Class 3\"]  # Replace with your actual class labels\n",
        "run_final_evaluation(df, best_max_features, class_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEMSQ7-9v3Lw"
      },
      "source": [
        "# BERT for Text Classification\n",
        "\n",
        "Using classification model, BERT. BERT (read more [here](https://arxiv.org/abs/1810.04805)) is a Transformer network (read more [here](https://arxiv.org/abs/1706.03762)). That means that it is a deep neural network in which each layer is actual comprised of a Transformer block, whose architecture is described in the linked paper - read more about it in this illustration [here](https://jalammar.github.io/illustrated-transformer/).\n",
        "\n",
        "BERT is useful for text classification because it generates a latent representation for every input token based on its context. The output of BERT is there an $Nx768$ dimensional matrix, where $N$ is the number of tokens in the sequence input, and 768 is the size of token vectors produced by BERT. (Note: other models use different sized representations. The larger the representation, the more precise they can be, but also the more resources they require to both train and evaluate). We can then use these latent representations as inputs to a downstream task (such as sentence classification).\n",
        "\n",
        "We perform sentence classification by evaluating the special classification token that we insert at the very beginning of sentences before passing them to BERT. The self-attention mechanism (see the previously linked articles for more information) allows for a latent representation of the classifier token to reflect the input text as a whole."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0NioMeDzSXk"
      },
      "outputs": [],
      "source": [
        "!pip install transformers tokenizers\n",
        "import torch\n",
        "import transformers\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXuR7Q9ZynYP"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    print('GPU available!')\n",
        "    device = torch.cuda.current_device()\n",
        "else:\n",
        "    print('GPU unavailable - CPU will be used for all calculations')\n",
        "    device = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q--JVwkMzqC6"
      },
      "source": [
        "Using a pre-trained bio-medical BERT model i.e. model PubMedBert (read about it [here](https://huggingface.co/microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract)). It has been trained on abstracts from PubMed!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcrxsbOixdf5"
      },
      "outputs": [],
      "source": [
        "#huggingface name for the model\n",
        "model_name = \"microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYM61xcBt39t"
      },
      "outputs": [],
      "source": [
        "# Load tokenizer directly\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, )\n",
        "\n",
        "max_length=128 #a typical value for short documents like abstracts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNHpgHi53K92"
      },
      "source": [
        "Tokenizing an entire corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJ2_rt9KFPAO"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = max_length\n",
        "def do_tokenisation(texts, max_length):\n",
        "    if not texts:  # Check if texts is empty\n",
        "        return None\n",
        "\n",
        "    tokeniser_output = tokenizer(\n",
        "        texts,\n",
        "        padding='max_length',  # pad shorter sequences to max_length\n",
        "        truncation=True,  # truncate longer sequences to max_length\n",
        "        max_length=max_length\n",
        "    )\n",
        "\n",
        "    for encoding in tokeniser_output:\n",
        "        tokeniser_output[encoding] = torch.tensor(tokeniser_output[encoding])\n",
        "\n",
        "    return tokeniser_output\n",
        "\n",
        "train_tokeniser_output = do_tokenisation(df[df.Split == \"Train\"].Abstract_Cleaned.tolist(), MAX_LEN)\n",
        "valid_tokeniser_output = do_tokenisation(df[df.Split == \"Valid\"].Abstract_Cleaned.tolist(), MAX_LEN)\n",
        "test_tokeniser_output = do_tokenisation(df[df.Split == \"Test\"].Abstract_Cleaned.tolist(), MAX_LEN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQiNot6L35C1"
      },
      "source": [
        "Example of the encodings produced by the tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzkLERWw35m2"
      },
      "outputs": [],
      "source": [
        "batch_idx = 5\n",
        "original_sentence = df.Abstract_Cleaned[batch_idx]\n",
        "print(f'Input sentence:\\n{original_sentence}\\n')\n",
        "tokens = train_tokeniser_output.tokens(batch_idx)\n",
        "print(f'Tokens:\\n{tokens}\\n')\n",
        "input_ids = train_tokeniser_output['input_ids'][batch_idx]\n",
        "print(f'Input IDs:\\n{input_ids}\\n')\n",
        "attention_mask = train_tokeniser_output['attention_mask'][batch_idx]\n",
        "print(f'Attention Mask:\\n{attention_mask}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdkkRc9YHT7S"
      },
      "outputs": [],
      "source": [
        "max_len_corpus = max(len(tokenizer.encode(text)) for text in df['Abstract_Cleaned'])\n",
        "print(\"Maximum length in the corpus:\", max_len_corpus)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsAX8p_74HxP"
      },
      "source": [
        "## Language Model\n",
        "\n",
        " Hugging Face API to load the pre-trained weights of a transformer language model for inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWiOdWCT5BYu"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
        "#AutoModelForSequenceClassification is an API that appends a linear classifer layer to\n",
        "#the classifier token of a BERT network. Alternately, one can do this onseself in torch\n",
        "#by creating a new class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOGCCwl75IFv"
      },
      "source": [
        "The ``config`` attribute contains hyperparameter values including vocabulary size, dropout probabilities, and architectural specifications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUQYZGGu5EW5"
      },
      "outputs": [],
      "source": [
        "model_config = AutoConfig.from_pretrained(model_name)\n",
        "print(model_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaauq_Lj5Yvu"
      },
      "outputs": [],
      "source": [
        "model_config.num_labels = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaT1x5VV5b78"
      },
      "source": [
        "The ``model`` object we use here is an instantiation of the pre-trained PubMedBert model with an extra classification layer added."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DK3Zqjpo5iHl"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForSequenceClassification.from_config(model_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Hh2ZcQG50Uv"
      },
      "outputs": [],
      "source": [
        "# the constructor function requires the parameters of the language model and the learning rate as input\n",
        "\n",
        "optimizer = AdamW(tuple(model.parameters()), lr=2e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtVZCuiu6Aat"
      },
      "outputs": [],
      "source": [
        "# here we define a simple subclass of the Pytorch Dataset object: the DataLoader by default will access the amount\n",
        "# of data points stored by instances of this subclass, as well as indexing it, so we have to overwrite the __len__\n",
        "# and __getitem__ methods to make sure it will behave as we would like\n",
        "\n",
        "class ClassificationDataset(Dataset):\n",
        "    def __init__(self, df, split):\n",
        "        super().__init__()\n",
        "        self.df = df[df.Split==split]\n",
        "        self.tokeniser_output = do_tokenisation(self.df.Abstract_Cleaned.tolist(), MAX_LEN)\n",
        "        self.labels = self.df.Year.values-2020\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        input_ids, att_mask = self.tokeniser_output[\"input_ids\"][idx], self.tokeniser_output[\"attention_mask\"][idx]\n",
        "        label = self.labels[idx]\n",
        "        return (input_ids, att_mask, label)\n",
        "\n",
        "train_dataset = ClassificationDataset(df,\"Train\")\n",
        "valid_dataset = ClassificationDataset(df,\"Valid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOx4fdqp8-uj"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 4\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Efc0UC7r7NQe"
      },
      "source": [
        "## Training a Classifier\n",
        "To fine-tune the PubMedBert word embeddings for our document classification task, we use the ``[CLS]`` token from the final layer of the transformer neural network to predict the relevant class for each sentence. To output class probabilities based on the word embedding vectors, a linear prediction layer is stacked on top of the transformer network, which will learn weight parameters $w$ that correspond to the optimal transformation of the ``[CLS]`` vector into a vector of scores for each class in the output space (usually called _logits_). To generate class probabilities from the logit vector, the [softmax function](https://en.wikipedia.org/wiki/Softmax_function) is applied:\n",
        "\n",
        "$$\n",
        "\\phi_w:\\mathbb{R}^{d_{\\text{EMB}}}\\rightarrow\\mathbb{R}^{d_{\\text{CLASS}}} \\\\\n",
        "\\text{Classifier}\\left(x_{\\text{CLS}}\\right)=\\text{softmax}\\left(\\phi_w\\left(x_{\\text{CLS}}\\right)\\right)\n",
        "$$\n",
        "\n",
        "For the model we use in this tutorial, we have embedding dimension $d_{\\text{EMB}}=768$ and because we have ten hallmarks of cancer plus the absence of a hallmark, we have output dimension $d_{\\text{CLASS}}=4$.\n",
        "\n",
        "To predict a single class, however, we just need to pick out the dimension of the logit vector with the highest score:\n",
        "\n",
        "$$\\text{Predicted Class}=\\text{argmax}\\left(\\phi\\left(x_{\\text{CLS}}\\right)\\right)$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFWAyhZ-tEDR"
      },
      "outputs": [],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhMS67oC7n-n"
      },
      "outputs": [],
      "source": [
        "N_EPOCHS = 20\n",
        "\n",
        "# progress bar for batches\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0vkWi5sL4f5"
      },
      "source": [
        "Training the model from scratch using PubmedBERT model configuration without pretrained weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVuvcBzZ8VKZ"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def train_model(model=None):\n",
        "    total_train_f1 = []\n",
        "    total_valid_f1 = []\n",
        "    total_train_loss = []\n",
        "    total_valid_loss = []\n",
        "\n",
        "    # reset the model if you run this cell more than once!\n",
        "    if model is None:\n",
        "        model = AutoModelForSequenceClassification.from_config(model_config).to(device)\n",
        "    optimizer = AdamW(tuple(model.parameters()), lr=2e-5)\n",
        "\n",
        "    for epoch in range(N_EPOCHS):\n",
        "        model.train()\n",
        "        train_f1 = []\n",
        "        train_loss = []\n",
        "        valid_f1 = []\n",
        "        valid_loss = []\n",
        "        print(f'Epoch {epoch}, training...')\n",
        "\n",
        "        # Training data\n",
        "        for input_ids, attention_masks, labels in tqdm(train_dataloader):\n",
        "            # forward pass\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_masks = attention_masks.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(\n",
        "                input_ids=input_ids, attention_mask=attention_masks, labels=labels\n",
        "            )\n",
        "\n",
        "            # backpropagation\n",
        "            loss = criterion(outputs.logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # metrics\n",
        "            predictions = outputs.logits.argmax(-1)\n",
        "            f1 = f1_score(labels.cpu(), predictions.cpu(), average='weighted')\n",
        "            logits = outputs.logits.cpu()  # retrieve data from the GPU\n",
        "            labels = labels.cpu()\n",
        "            predictions = logits.argmax(-1)\n",
        "            train_f1.append(f1)\n",
        "            train_loss.append(loss.item())\n",
        "\n",
        "        epoch_f1_train = sum(train_f1) / len(train_f1)\n",
        "        epoch_loss_train = sum(train_loss) / len(train_loss)\n",
        "        total_train_f1.append(epoch_f1_train)\n",
        "        total_train_loss.append(epoch_loss_train)\n",
        "\n",
        "        model.eval()\n",
        "        print(f'Epoch {epoch}, evaluating...')\n",
        "        # Validation data\n",
        "        for input_ids, attention_masks, labels in tqdm(valid_dataloader):\n",
        "            with torch.no_grad():  # this context manager deactivates the backpropagation-related elements of the tensors\n",
        "                outputs = model(\n",
        "                    input_ids=input_ids.to(device), attention_mask=attention_masks.to(device)\n",
        "                )\n",
        "                loss = criterion(outputs.logits, labels.to(device))\n",
        "                predictions = outputs.logits.argmax(-1)\n",
        "                f1 = f1_score(labels.cpu(), predictions.cpu(), average='weighted')\n",
        "                valid_f1.append(f1)\n",
        "                valid_loss.append(loss.item())\n",
        "\n",
        "        epoch_f1_valid = sum(valid_f1) / len(valid_f1)\n",
        "        epoch_loss_valid = sum(valid_loss) / len(valid_loss)\n",
        "        total_valid_f1.append(epoch_f1_valid)\n",
        "        total_valid_loss.append(epoch_loss_valid)\n",
        "        print(f'Epoch {epoch}: training set F1={round(epoch_f1_train, 3)}, validation set F1={round(epoch_f1_valid, 3)}')\n",
        "\n",
        "    return model, total_train_f1, total_valid_f1, total_train_loss, total_valid_loss\n",
        "\n",
        "model, total_train_f1, total_valid_f1, total_train_loss, total_valid_loss = train_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RgkjcK_Lv9L"
      },
      "outputs": [],
      "source": [
        "ax = plt.gca()\n",
        "twinx = ax.twinx()\n",
        "twinx.plot(total_train_loss,label=\"Loss Train\", linestyle=\"dashed\")\n",
        "twinx.plot(total_valid_loss,label=\"Loss Valid\", linestyle=\"dashed\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"F1/Loss\")\n",
        "plt.title(\"Evolution of training and validation performances over time\")\n",
        "ax.legend()\n",
        "twinx.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RVcKHemJvKz"
      },
      "outputs": [],
      "source": [
        "#For PubMedBert\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Function to get predictions from the model\n",
        "def get_predictions(model, dataloader):\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for input_ids, attention_masks, labels in tqdm(dataloader):\n",
        "            outputs = model(\n",
        "                input_ids=input_ids.to(device), attention_mask=attention_masks.to(device)\n",
        "            )\n",
        "            predictions.extend(outputs.logits.argmax(-1).cpu().numpy())\n",
        "            true_labels.extend(labels.numpy())\n",
        "\n",
        "    return np.array(predictions), np.array(true_labels)\n",
        "\n",
        "# Get predictions for the test set\n",
        "test_dataset = ClassificationDataset(df, \"Test\")\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "predictions_bert, true_labels_bert = get_predictions(model, test_dataloader)\n",
        "\n",
        "# Confusion matrix for PubMedBert\n",
        "cm_bert = confusion_matrix(true_labels_bert, predictions_bert)\n",
        "print(\"Confusion Matrix for PubMedBert:\")\n",
        "print(cm_bert)\n",
        "\n",
        "# Visualize the confusion matrix using Seaborn's heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_bert, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Class 0\", \"Class 1\", \"Class 2\", \"Class 3\"],\n",
        "            yticklabels=[\"Class 0\", \"Class 1\", \"Class 2\", \"Class 3\"])\n",
        "plt.title(\"Confusion Matrix for PubMedBert without pretrained weights\")\n",
        "plt.xlabel(\"Predicted Class\")\n",
        "plt.ylabel(\"True Class\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpnB_5VMO0GS"
      },
      "source": [
        "The results here show that the model is heavily biased towards class 1 and sample size is too little to train the model from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErlSprs5IC2S"
      },
      "source": [
        "# **Using BiomedBERT with pretrained weights**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1qyu4QEH644"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "model_name = \"microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "max_length = 128\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Running on: {device}\")\n",
        "\n",
        "def do_tokenisation(texts, max_length):\n",
        "    return tokenizer(texts, padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
        "\n",
        "class ClassificationDataset(Dataset):\n",
        "    def __init__(self, df, split):\n",
        "        self.df = df[df.Split == split]\n",
        "        self.tokeniser_output = do_tokenisation(self.df.Abstract.tolist(), max_length)\n",
        "        self.labels = self.df.Year.values - 2020\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.tokeniser_output[\"input_ids\"][idx], self.tokeniser_output[\"attention_mask\"][idx], self.labels[idx])\n",
        "\n",
        "# Data setup\n",
        "df[\"Abstract_Cleaned\"] = df[\"Abstract\"].apply(clean)\n",
        "train_dataset = ClassificationDataset(df, \"Train\")\n",
        "valid_dataset = ClassificationDataset(df, \"Valid\")\n",
        "test_dataset = ClassificationDataset(df, \"Test\")\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=16, shuffle=False)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "def train_model():\n",
        "    # Load pretrained weights\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=4).to(device)\n",
        "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    N_EPOCHS = 20\n",
        "    patience = 4\n",
        "    best_valid_f1 = 0.0\n",
        "    patience_counter = 0\n",
        "\n",
        "    total_train_f1, total_valid_f1, total_train_loss, total_valid_loss = [], [], [], []\n",
        "\n",
        "    for epoch in range(N_EPOCHS):\n",
        "        model.train()\n",
        "        train_f1, train_loss = [], []\n",
        "        for input_ids, attention_masks, labels in tqdm(train_dataloader, desc=f\"Epoch {epoch} Training\"):\n",
        "            input_ids, attention_masks, labels = input_ids.to(device), attention_masks.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_masks, labels=labels)\n",
        "            loss = criterion(outputs.logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            predictions = outputs.logits.argmax(-1)\n",
        "            f1 = f1_score(labels.cpu(), predictions.cpu(), average=\"weighted\")\n",
        "            train_f1.append(f1)\n",
        "            train_loss.append(loss.item())\n",
        "\n",
        "        model.eval()\n",
        "        valid_f1, valid_loss = [], []\n",
        "        for input_ids, attention_masks, labels in tqdm(valid_dataloader, desc=f\"Epoch {epoch} Validation\"):\n",
        "            with torch.no_grad():\n",
        "                outputs = model(input_ids.to(device), attention_mask=attention_masks.to(device))\n",
        "                loss = criterion(outputs.logits, labels.to(device))\n",
        "                predictions = outputs.logits.argmax(-1)\n",
        "                f1 = f1_score(labels.cpu(), predictions.cpu(), average=\"weighted\")\n",
        "                valid_f1.append(f1)\n",
        "                valid_loss.append(loss.item())\n",
        "\n",
        "        epoch_train_f1 = sum(train_f1) / len(train_f1)\n",
        "        epoch_valid_f1 = sum(valid_f1) / len(valid_f1)\n",
        "        print(f\"Epoch {epoch}: train F1={epoch_train_f1:.3f}, valid F1={epoch_valid_f1:.3f}\")\n",
        "\n",
        "        if epoch_valid_f1 > best_valid_f1:\n",
        "            best_valid_f1 = epoch_valid_f1\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), \"best_model_pretrained.pt\")\n",
        "            print(f\"New best validation F1: {best_valid_f1:.3f}, model saved\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"No improvement in validation F1, patience counter: {patience_counter}/{patience}\")\n",
        "            if patience_counter >= patience:\n",
        "                print(\"Early stopping triggered\")\n",
        "                model.load_state_dict(torch.load(\"best_model_pretrained.pt\"))\n",
        "                break\n",
        "\n",
        "        total_train_f1.append(epoch_train_f1)\n",
        "        total_valid_f1.append(epoch_valid_f1)\n",
        "        total_train_loss.append(sum(train_loss) / len(train_loss))\n",
        "        total_valid_loss.append(sum(valid_loss) / len(valid_loss))\n",
        "\n",
        "    return model, total_train_f1, total_valid_f1, total_train_loss, total_valid_loss\n",
        "\n",
        "# Function to get predictions\n",
        "def get_predictions(model, dataloader):\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for input_ids, attention_masks, labels in tqdm(dataloader, desc=\"Getting Predictions\"):\n",
        "            outputs = model(input_ids=input_ids.to(device), attention_mask=attention_masks.to(device))\n",
        "            predictions.extend(outputs.logits.argmax(-1).cpu().numpy())\n",
        "            true_labels.extend(labels.numpy())\n",
        "    return np.array(predictions), np.array(true_labels)\n",
        "\n",
        "# Train and evaluate the pretrained model\n",
        "print(\"Training with pretrained weights...\")\n",
        "model_pretrained, _, _, _, _ = train_model()\n",
        "\n",
        "# Get predictions for the pretrained model\n",
        "predictions_pretrained, true_labels_pretrained = get_predictions(model_pretrained, test_dataloader)\n",
        "\n",
        "# Confusion matrix for PubMedBERT with pretrained weights\n",
        "cm_pretrained = confusion_matrix(true_labels_pretrained, predictions_pretrained)\n",
        "print(\"Confusion Matrix for PubMedBERT with Pretrained Weights:\")\n",
        "print(cm_pretrained)\n",
        "\n",
        "# Plotting the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_pretrained, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=[\"2020\", \"2021\", \"2022\", \"2023\"],  # Years instead of generic classes\n",
        "            yticklabels=[\"2020\", \"2021\", \"2022\", \"2023\"])\n",
        "plt.title(\"Confusion Matrix for PubMedBERT with Pretrained Weights\")\n",
        "plt.xlabel(\"Predicted Year\")\n",
        "plt.ylabel(\"True Year\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5vydYGSU4to"
      },
      "source": [
        "The pretrained **PubMedBERT** model, fine-tuned on a large medical dataset, achieved an F1 score of 0.72 on the validation set, outperforming both model with PubmedBERT cofig but trained from scratch without pretrained weights and TF-IDF classifiers. Pretraining allows PubMedBERT to leverage domain-specific knowledge, improving its performance."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}